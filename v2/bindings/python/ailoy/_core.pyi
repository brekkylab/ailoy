# This file is automatically generated by pyo3_stub_gen
# ruff: noqa: E501, F401

import builtins
import typing
from enum import Enum

class Agent:
    @property
    def lm(self) -> LangModel: ...
    @property
    def tools(self) -> builtins.list[Tool]: ...
    def __new__(cls, lm:LangModel, tools:typing.Optional[typing.Sequence[Tool]]=None) -> Agent: ...
    @classmethod
    def create(cls, lm:LangModel, tools:typing.Optional[typing.Sequence[Tool]]=None) -> typing.Awaitable[Agent]: ...
    def __repr__(self) -> builtins.str: ...
    def add_tools(self, tools:typing.Sequence[Tool]) -> None: ...
    def add_tool(self, tool:Tool) -> None: ...
    def remove_tools(self, tool_names:typing.Sequence[builtins.str]) -> None: ...
    def remove_tool(self, tool_name:builtins.str) -> None: ...
    def run(self, contents:typing.Sequence[Part], config:typing.Optional[InferenceConfig]=None) -> AgentRunIterator: ...
    def run_sync(self, contents:typing.Sequence[Part], config:typing.Optional[InferenceConfig]=None) -> AgentRunSyncIterator: ...

class AgentResponse:
    r"""
    The yielded value from agent.run().
    """
    @property
    def delta(self) -> MessageDelta:
        r"""
        The message delta per iteration.
        """
    @property
    def finish_reason(self) -> typing.Optional[FinishReason]:
        r"""
        Optional finish reason. If this is Some, the message aggregation is finalized and stored in `aggregated`.
        """
    @property
    def aggregated(self) -> typing.Optional[Message]:
        r"""
        Optional aggregated message.
        """
    def __repr__(self) -> builtins.str: ...

class AgentRunIterator:
    def __aiter__(self) -> AgentRunIterator: ...
    def __anext__(self) -> typing.Awaitable[AgentResponse]: ...

class AgentRunSyncIterator:
    def __iter__(self) -> AgentRunSyncIterator: ...
    def __next__(self) -> AgentResponse: ...

class CacheProgress:
    @property
    def comment(self) -> builtins.str: ...
    @property
    def current(self) -> builtins.int: ...
    @property
    def total(self) -> builtins.int: ...
    def __repr__(self) -> builtins.str: ...

class Document:
    def __new__(cls, id:builtins.str, text:builtins.str, title:typing.Optional[builtins.str]=None) -> Document: ...

class DocumentPolyfill:
    r"""
    Provides a polyfill for LLMs that do not natively support the Document feature.
    """
    @property
    def system_message_template(self) -> typing.Optional[builtins.str]: ...
    @property
    def query_message_template(self) -> typing.Optional[builtins.str]: ...
    @system_message_template.setter
    def system_message_template(self, value: typing.Optional[builtins.str]) -> None: ...
    @query_message_template.setter
    def query_message_template(self, value: typing.Optional[builtins.str]) -> None: ...
    def __new__(cls) -> DocumentPolyfill: ...

class EmbeddingModel:
    @classmethod
    def CreateLocal(cls, model_name:builtins.str, progress_callback:typing.Callable[[CacheProgress], None]=None) -> typing.Awaitable[EmbeddingModel]: ...
    @classmethod
    def CreateLocalSync(cls, model_name:builtins.str, progress_callback:typing.Callable[[CacheProgress], None]=None) -> EmbeddingModel: ...
    async def run(self, text:builtins.str) -> builtins.list[builtins.float]: ...
    def run_sync(self, text:builtins.str) -> builtins.list[builtins.float]: ...

class Grammar:
    class Plain(Grammar):
        __match_args__ = ((),)
        def __new__(cls) -> Grammar.Plain: ...
    
    class JSON(Grammar):
        __match_args__ = ((),)
        def __new__(cls) -> Grammar.JSON: ...
    
    class JSONSchema(Grammar):
        __match_args__ = ("schema",)
        @property
        def schema(self) -> builtins.str: ...
        def __new__(cls, schema:builtins.str) -> Grammar.JSONSchema: ...
    
    class Regex(Grammar):
        __match_args__ = ("regex",)
        @property
        def regex(self) -> builtins.str: ...
        def __new__(cls, regex:builtins.str) -> Grammar.Regex: ...
    
    class CFG(Grammar):
        __match_args__ = ("cfg",)
        @property
        def cfg(self) -> builtins.str: ...
        def __new__(cls, cfg:builtins.str) -> Grammar.CFG: ...
    
    ...

class InferenceConfig:
    @property
    def document_polyfill(self) -> typing.Optional[DocumentPolyfill]: ...
    @property
    def think_effort(self) -> typing.Optional[ThinkEffort]: ...
    @property
    def temperature(self) -> typing.Optional[builtins.float]: ...
    @property
    def top_p(self) -> typing.Optional[builtins.float]: ...
    @property
    def max_tokens(self) -> typing.Optional[builtins.int]: ...
    @property
    def grammar(self) -> typing.Optional[Grammar]: ...
    @document_polyfill.setter
    def document_polyfill(self, value: typing.Optional[DocumentPolyfill]) -> None: ...
    @think_effort.setter
    def think_effort(self, value: typing.Optional[ThinkEffort]) -> None: ...
    @temperature.setter
    def temperature(self, value: typing.Optional[builtins.float]) -> None: ...
    @top_p.setter
    def top_p(self, value: typing.Optional[builtins.float]) -> None: ...
    @max_tokens.setter
    def max_tokens(self, value: typing.Optional[builtins.int]) -> None: ...
    @grammar.setter
    def grammar(self, value: typing.Optional[Grammar]) -> None: ...
    def __new__(cls, document_polyfill:typing.Optional[DocumentPolyfill]=None, think_effort:typing.Optional[ThinkEffort]=None, temperature:typing.Optional[builtins.float]=None, top_p:typing.Optional[builtins.float]=None, max_tokens:typing.Optional[builtins.int]=None) -> InferenceConfig: ...

class LangModel:
    @classmethod
    def CreateLocal(cls, model_name:builtins.str, progress_callback:typing.Callable[[CacheProgress], None]=None) -> typing.Awaitable[LangModel]: ...
    @classmethod
    def CreateLocalSync(cls, model_name:builtins.str, progress_callback:typing.Callable[[CacheProgress], None]=None) -> LangModel: ...
    @classmethod
    def CreateStreamAPI(cls, spec:APISpecification, model_name:builtins.str, api_key:builtins.str) -> LangModel: ...
    def run(self, messages:typing.Sequence[Message], tools:typing.Optional[typing.Sequence[ToolDesc]]=None, documents:typing.Optional[typing.Sequence[Document]]=None, config:typing.Optional[InferenceConfig]=None) -> LangModelRunIterator: ...
    def run_sync(self, messages:typing.Sequence[Message], tools:typing.Optional[typing.Sequence[ToolDesc]]=None, documents:typing.Optional[typing.Sequence[Document]]=None, config:typing.Optional[InferenceConfig]=None) -> LangModelRunSyncIterator: ...
    def __repr__(self) -> builtins.str: ...

class LangModelRunIterator:
    def __aiter__(self) -> LangModelRunIterator: ...
    def __anext__(self) -> typing.Awaitable[MessageOutput]: ...

class LangModelRunSyncIterator:
    def __iter__(self) -> LangModelRunSyncIterator: ...
    def __next__(self) -> MessageOutput: ...

class MCPClient:
    @property
    def tools(self) -> builtins.list[Tool]: ...
    def __repr__(self) -> builtins.str: ...
    @classmethod
    def from_stdio(cls, command:builtins.str, args:typing.Sequence[builtins.str]) -> typing.Awaitable[MCPClient]: ...
    @classmethod
    def from_streamable_http(cls, url:builtins.str) -> typing.Awaitable[MCPClient]: ...
    def get_tool(self, name:builtins.str) -> typing.Optional[Tool]: ...

class Message:
    r"""
    A chat message generated by a user, model, or tool.
    
    `Message` is the concrete, non-streaming container used by the application to store, transmit, or feed structured content into models or tools.
    It can represent various kinds of messages, including user input, assistant responses, tool-call outputs, or signed *thinking* metadata.
    
    Note that many different kinds of messages can be produced.
    For example, a language model may internally generate a `thinking` trace before emitting its final output, in order to improve reasoning accuracy.
    In other cases, a model may produce *function calls* — structured outputs that instruct external tools to perform specific actions.
    
    This struct is designed to handle all of these situations in a unified way.
    
    # Example
    
    ## Rust
    ```rust
    let msg = Message::new(Role::User).with_contents([Part::text("hello")]);
    assert_eq!(msg.role, Role::User);
    assert_eq!(msg.contents.len(), 1);
    ```
    """
    @property
    def role(self) -> Role:
        r"""
        Author of the message.
        """
    @property
    def contents(self) -> builtins.list[Part]:
        r"""
        Primary message parts (e.g., text, image, value, or function).
        """
    @property
    def id(self) -> typing.Optional[builtins.str]:
        r"""
        Optional stable identifier for deduplication or threading.
        """
    @property
    def thinking(self) -> typing.Optional[builtins.str]:
        r"""
        Internal “thinking” text used by some models before producing final output.
        """
    @property
    def tool_calls(self) -> typing.Optional[builtins.list[Part]]:
        r"""
        Tool-call parts emitted alongside the main contents.
        """
    @property
    def signature(self) -> typing.Optional[builtins.str]:
        r"""
        Optional signature for the `thinking` field.
        
        This is only applicable to certain LLM APIs that require a signature as part of the `thinking` payload.
        """
    @property
    def contents(self) -> builtins.list[Part]: ...
    @property
    def thinking(self) -> typing.Optional[builtins.str]: ...
    @property
    def tool_calls(self) -> builtins.list[Part]: ...
    @property
    def id(self) -> typing.Optional[builtins.str]: ...
    @role.setter
    def role(self, value: Role) -> None:
        r"""
        Author of the message.
        """
    @contents.setter
    def contents(self, value: builtins.list[Part]) -> None:
        r"""
        Primary message parts (e.g., text, image, value, or function).
        """
    @id.setter
    def id(self, value: typing.Optional[builtins.str]) -> None:
        r"""
        Optional stable identifier for deduplication or threading.
        """
    @thinking.setter
    def thinking(self, value: typing.Optional[builtins.str]) -> None:
        r"""
        Internal “thinking” text used by some models before producing final output.
        """
    @tool_calls.setter
    def tool_calls(self, value: typing.Optional[builtins.list[Part]]) -> None:
        r"""
        Tool-call parts emitted alongside the main contents.
        """
    @signature.setter
    def signature(self, value: typing.Optional[builtins.str]) -> None:
        r"""
        Optional signature for the `thinking` field.
        
        This is only applicable to certain LLM APIs that require a signature as part of the `thinking` payload.
        """
    @contents.setter
    def contents(self, value: builtins.list[Part]) -> None: ...
    @thinking.setter
    def thinking(self, value: builtins.str) -> None: ...
    @tool_calls.setter
    def tool_calls(self, value: builtins.list[Part]) -> None: ...
    @id.setter
    def id(self, value: typing.Optional[builtins.str]) -> None: ...
    def __new__(cls, role:Role, id:typing.Optional[builtins.str]=None, thinking:typing.Optional[builtins.str]=None, contents:typing.Optional[typing.Sequence[Part]]=None, tool_calls:typing.Optional[typing.Sequence[Part]]=None, signature:typing.Optional[builtins.str]=None) -> Message: ...
    def __repr__(self) -> builtins.str: ...
    def append_contents(self, part:Part) -> None: ...
    def append_tool_call(self, part:Part) -> None: ...

class MessageDelta:
    r"""
    A streaming, incremental update to a [`Message`].
    
    `MessageDelta` accumulates partial outputs (text chunks, tool-call fragments, IDs, signatures, etc.) until they can be materialized as a full [`Message`].
    It implements [`Delta`] to support associative aggregation.
    
    # Aggregation Rules
    - `role`: merging two distinct roles fails.
    - `thinking`: concatenated in arrival order.
    - `contents`/`tool_calls`: last element is aggregated with the incoming delta when both are compatible (e.g., Text+Text, Function+Function with matching ID policy), otherwise appended as a new fragment.
    - `id`/`signature`: last-writer-wins.
    
    # Finalization
    - `finish()` converts the accumulated deltas into a fully-formed [`Message`].
      Fails if required fields (e.g., `role`) are missing or inner deltas cannot be finalized.
    
    # Examples
    ```rust
    let d1 = MessageDelta::new().with_role(Role::Assistant).with_contents([PartDelta::Text { text: "Hel".into() }]);
    let d2 = MessageDelta::new().with_contents([PartDelta::Text { text: "lo".into() }]);
    
    let merged = d1.aggregate(d2).unwrap();
    let msg = merged.finish().unwrap();
    assert_eq!(msg.contents[0].as_text().unwrap(), "Hello");
    ```
    """
    @property
    def role(self) -> typing.Optional[Role]: ...
    @property
    def id(self) -> typing.Optional[builtins.str]: ...
    @property
    def thinking(self) -> typing.Optional[builtins.str]: ...
    @property
    def contents(self) -> builtins.list[PartDelta]: ...
    @property
    def tool_calls(self) -> builtins.list[PartDelta]: ...
    @property
    def signature(self) -> typing.Optional[builtins.str]: ...
    @role.setter
    def role(self, value: typing.Optional[Role]) -> None: ...
    @id.setter
    def id(self, value: typing.Optional[builtins.str]) -> None: ...
    @thinking.setter
    def thinking(self, value: typing.Optional[builtins.str]) -> None: ...
    @contents.setter
    def contents(self, value: builtins.list[PartDelta]) -> None: ...
    @tool_calls.setter
    def tool_calls(self, value: builtins.list[PartDelta]) -> None: ...
    @signature.setter
    def signature(self, value: typing.Optional[builtins.str]) -> None: ...
    def __new__(cls, role:typing.Optional[Role]=None, id:typing.Optional[builtins.str]=None, thinking:typing.Optional[builtins.str]=None, contents:typing.Optional[typing.Sequence[PartDelta]]=None, tool_calls:typing.Optional[typing.Sequence[PartDelta]]=None, signature:typing.Optional[builtins.str]=None) -> MessageDelta: ...
    def __repr__(self) -> builtins.str: ...
    def __add__(self, other:MessageDelta) -> MessageDelta: ...
    def to_message(self) -> Message: ...

class MessageOutput:
    r"""
    A container for a streamed message delta and its termination signal.
    
    During streaming, `delta` carries the incremental payload; once a terminal
    condition is reached, `finish_reason` may be populated to explain why.
    
    # Examples
    ```rust
    let mut out = MessageOutput::new();
    out.delta = MessageDelta::new().with_role(Role::Assistant).with_contents([PartDelta::Text { text: "Hi".into() }]);
    assert!(out.finish_reason.is_none());
    ```
    
    # Lifecycle
    - While streaming: `finish_reason` is typically `None`.
    - On completion: `finish_reason` is set; callers can then `finish()` the delta to obtain a concrete [`Message`].
    """
    @property
    def delta(self) -> MessageDelta: ...
    @property
    def finish_reason(self) -> typing.Optional[FinishReason]: ...
    @property
    def delta(self) -> MessageDelta: ...
    @property
    def finish_reason(self) -> typing.Optional[FinishReason]: ...
    @delta.setter
    def delta(self, value: MessageDelta) -> None: ...
    @finish_reason.setter
    def finish_reason(self, value: typing.Optional[FinishReason]) -> None: ...
    def __repr__(self) -> builtins.str: ...

class Part:
    r"""
    Represents a semantically meaningful content unit exchanged between the model and the user.
    
    Conceptually, each `Part` encapsulates a piece of **data** that contributes
    to a chat message — such as text, a function invocation, or an image.  
    
    For example, a single message consisting of a sequence like  
    `(text..., image, text...)` is represented as a `Message` containing
    an array of three `Part` elements.
    
    Note that a `Part` does **not** carry "intent", such as "reasoning" or "tool call".
    These higher-level semantics are determined by the context of a [`Message`].
    
    # Example
    
    ## Rust
    ```rust
    let part = Part::text("Hello, world!");
    assert!(part.is_text());
    ```
    """
    @property
    def part_type(self) -> builtins.str: ...
    def __repr__(self) -> builtins.str: ...
    class Text(Part):
        r"""
        Plain utf-8 encoded text.
        """
        __match_args__ = ("text",)
        @property
        def text(self) -> builtins.str: ...
        def __new__(cls, text:builtins.str) -> Part.Text: ...
    
    class Function(Part):
        r"""
        Represents a structured function call to an external tool.
        
        Many language models (LLMs) use a **function calling** mechanism to extend their capabilities.
        When an LLM decides to use external *tools*, it produces a structured output called a `function`.
        A function conventionally consists of two fields: a `name`, and an `arguments` field formatted as JSON.
        This is conceptually similar to making an HTTP POST request, where the request body carries a single JSON object.
        
        This struct models that convention, representing a function invocation request
        from an LLM to an external tool or API.

CacheResultT = typing.TypeVar("CacheResultT")
        
        # Examples
        ```rust
        let f = PartFunction {
            name: "translate".to_string(),
            arguments: Value::from_json(r#"{"source": "hello", "lang": "cn"}"#).unwrap(),
        };
        ```
        """
        __match_args__ = ("id", "function",)
        @property
        def id(self) -> typing.Optional[builtins.str]: ...
        @property
        def function(self) -> dict[typing.Literal["name", "arguments"], typing.Union[str, typing.Any]]: ...
        def __new__(cls, id:typing.Optional[builtins.str], function:dict[typing.Literal["name", "arguments"], typing.Union[str, typing.Any]]) -> Part.Function: ...
    
    class Value(Part):
        r"""
        Holds a structured data value, typically considered as a JSON structure.
        """
        __match_args__ = ("value",)
        @property
        def value(self) -> typing.Any: ...
        def __new__(cls, value:typing.Any) -> Part.Value: ...
    
    class Image(Part):
        r"""
        Contains an image payload or reference used within a message part.
        The image may be provided as raw binary data or an encoded format (e.g., PNG, JPEG),
        or as a reference via a URL. Optional metadata can be included alongside the image.
        """
        __match_args__ = ("image",)
        @property
        def image(self) -> PartImage: ...
        def __new__(cls, image:PartImage) -> Part.Image: ...
    

class PartDelta:
    r"""
    Represents a partial or incremental update (delta) of a [`Part`].
    
    This type enables composable, streaming updates to message parts.
    For example, text may be produced token-by-token, or a function call
    may be emitted gradually as its arguments stream in.
    
    # Example
    
    ## Rust
    ```rust
    let d1 = PartDelta::Text { text: "Hel".into() };
    let d2 = PartDelta::Text { text: "lo".into() };
    let merged = d1.aggregate(d2).unwrap();
    assert_eq!(merged.to_text().unwrap(), "Hello");
    ```
    
    # Error Handling
    Aggregation or finalization may return an error if incompatible deltas
    (e.g. mismatched function IDs) are combined or invalid JSON arguments are given.
    """
    @property
    def part_type(self) -> builtins.str: ...
    def __repr__(self) -> builtins.str: ...
    class Text(PartDelta):
        r"""
        Incremental text fragment.
        """
        __match_args__ = ("text",)
        @property
        def text(self) -> builtins.str: ...
        def __new__(cls, text:builtins.str) -> PartDelta.Text: ...
    
    class Function(PartDelta):
        r"""
        Incremental function call fragment.
        """
        __match_args__ = ("id", "function",)
        @property
        def id(self) -> typing.Optional[builtins.str]: ...
        @property
        def function(self) -> PartDeltaFunction: ...
        def __new__(cls, id:typing.Optional[builtins.str], function:PartDeltaFunction) -> PartDelta.Function: ...
    
    class Value(PartDelta):
        r"""
        JSON-like value update.
        """
        __match_args__ = ("value",)
        @property
        def value(self) -> typing.Any: ...
        def __new__(cls, value:typing.Any) -> PartDelta.Value: ...
    
    class Null(PartDelta):
        r"""
        Placeholder representing no data yet.
        """
        __match_args__ = ((),)
        def __new__(cls) -> PartDelta.Null: ...
    

class PartDeltaFunction:
    r"""
    Represents an incremental update (delta) of a function part.
    
    This type is used during streaming or partial message generation, when function calls are being streamed as text chunks or partial JSON fragments.
    
    # Variants
    * `Verbatim(String)` — Raw text content, typically a partial JSON fragment.
    * `WithStringArgs { name, arguments }` — Function name and its serialized arguments as strings.
    * `WithParsedArgs { name, arguments }` — Function name and parsed arguments as a `Value`.
    
    # Use Case
    When the model streams out a function call response (e.g., `"function_call":{"name":...}`),
    the incremental deltas can be aggregated until the full function payload is formed.
    
    # Example
    ```rust
    let delta = PartDeltaFunction::WithStringArgs {
        name: "translate".into(),
        arguments: r#"{"text":"hi"}"#.into(),
    };
    `
    """
    class Verbatim(PartDeltaFunction):
        __match_args__ = ("text",)
        @property
        def text(self) -> builtins.str: ...
        def __new__(cls, text:builtins.str) -> PartDeltaFunction.Verbatim: ...
    
    class WithStringArgs(PartDeltaFunction):
        __match_args__ = ("name", "arguments",)
        @property
        def name(self) -> builtins.str: ...
        @property
        def arguments(self) -> builtins.str: ...
        def __new__(cls, name:builtins.str, arguments:builtins.str) -> PartDeltaFunction.WithStringArgs: ...
    
    class WithParsedArgs(PartDeltaFunction):
        __match_args__ = ("name", "arguments",)
        @property
        def name(self) -> builtins.str: ...
        @property
        def arguments(self) -> typing.Any: ...
        def __new__(cls, name:builtins.str, arguments:typing.Any) -> PartDeltaFunction.WithParsedArgs: ...
    
    ...

class PartImage:
    r"""
    Represents the image data contained in a [`Part`].
    
    `PartImage` provides structured access to image data.
    Currently, it only implments "binary" types.
    
    # Example
    ```rust
    let part = Part::image_binary(640, 480, "rgb", (0..640*480*3).map(|i| (i % 255) as u8)).unwrap();
    
    if let Some(img) = part.as_image() {
        assert_eq!(img.height(), 640);
        assert_eq!(img.width(), 480);
    }
    ```
    """
    class Binary(PartImage):
        __match_args__ = ("height", "width", "colorspace", "data",)
        @property
        def height(self) -> builtins.int: ...
        @property
        def width(self) -> builtins.int: ...
        @property
        def colorspace(self) -> typing.Literal["grayscale", "rgb", "rgba"]: ...
        @property
        def data(self) -> typing.Any: ...
        def __new__(cls, height:builtins.int, width:builtins.int, colorspace:typing.Literal["grayscale", "rgb", "rgba"], data:typing.Any) -> PartImage.Binary: ...
    
    ...

class Tool:
    @classmethod
    def new_py_function(cls, desc:ToolDesc, func:typing.Any) -> Tool: ...
    def __repr__(self) -> builtins.str: ...
    def get_description(self) -> ToolDesc: ...
    def __call__(self, **kwargs) -> typing.Awaitable[typing.Any]: ...
    def call(self, **kwargs) -> typing.Awaitable[typing.Any]: ...
    def call_sync(self, **kwargs) -> typing.Any: ...
    @staticmethod
    def terminal() -> Tool: ...

class ToolDesc:
    r"""
    Describes a **tool** (or function) that a language model can invoke.
    
    `ToolDesc` defines the schema, behavior, and input/output specification of a callable
    external function, allowing an LLM to understand how to use it.
    
    The primary role of this struct is to describe to the LLM what a *tool* does,
    how it can be invoked, and what input (`parameters`) and output (`returns`) schemas it expects.
    
    The format follows the same **schema conventions** used by Hugging Face’s
    `transformers` library, as well as APIs such as *OpenAI* and *Anthropic*.
    The `parameters` and `returns` fields are typically defined using **JSON Schema**.
    
    We provide a builder [`ToolDescBuilder`] helper for convenient and fluent construction.
    Please refer to [`ToolDescBuilder`].
    
    # Example
    ```rust
    use crate::value::{ToolDescBuilder, to_value};
    
    let desc = ToolDescBuilder::new("temperature")
        .description("Get the current temperature for a given city")
        .parameters(to_value!({
            "type": "object",
            "properties": {
                "location": {
                    "type": "string",
                    "description": "The city name"
                },
                "unit": {
                    "type": "string",
                    "description": "Temperature unit (default: Celsius)",
                    "enum": ["Celsius", "Fahrenheit"]
                }
            },
            "required": ["location"]
        }))
        .returns(to_value!({
            "type": "number"
        }))
        .build();
    
    assert_eq!(desc.name, "temperature");
    ```
    """
    @property
    def name(self) -> builtins.str: ...
    @property
    def description(self) -> typing.Optional[builtins.str]: ...
    @property
    def parameters(self) -> dict: ...
    @property
    def returns(self) -> typing.Optional[dict]: ...
    def __new__(cls, name:builtins.str, description:typing.Optional[builtins.str], parameters:dict, *, returns:typing.Optional[dict]=None) -> ToolDesc: ...
    def __repr__(self) -> builtins.str: ...

class VectorStore:
    @classmethod
    def new_faiss(cls, dim:builtins.int) -> VectorStore: ...
    @classmethod
    def new_chroma(cls, url:builtins.str, collection_name:typing.Optional[builtins.str]) -> VectorStore: ...
    def add_vector(self, input:VectorStoreAddInput) -> builtins.str: ...
    def add_vectors(self, inputs:typing.Sequence[VectorStoreAddInput]) -> builtins.list[builtins.str]: ...
    def get_by_id(self, id:builtins.str) -> typing.Optional[VectorStoreGetResult]: ...
    def get_by_ids(self, ids:typing.Sequence[builtins.str]) -> builtins.list[VectorStoreGetResult]: ...
    def retrieve(self, query_embedding:typing.Sequence[builtins.float], top_k:builtins.int) -> builtins.list[VectorStoreRetrieveResult]: ...
    def batch_retrieve(self, query_embeddings:typing.Sequence[typing.Sequence[builtins.float]], top_k:builtins.int) -> builtins.list[builtins.list[VectorStoreRetrieveResult]]: ...
    def remove_vector(self, id:builtins.str) -> None: ...
    def remove_vectors(self, ids:typing.Sequence[builtins.str]) -> None: ...
    def clear(self) -> None: ...
    def count(self) -> builtins.int: ...

class VectorStoreAddInput:
    @property
    def embedding(self) -> builtins.list[builtins.float]: ...
    @property
    def document(self) -> builtins.str: ...
    @property
    def metadata(self) -> typing.Optional[builtins.dict[builtins.str, typing.Any]]: ...
    @embedding.setter
    def embedding(self, value: builtins.list[builtins.float]) -> None: ...
    @document.setter
    def document(self, value: builtins.str) -> None: ...
    @metadata.setter
    def metadata(self, value: typing.Optional[builtins.dict[builtins.str, typing.Any]]) -> None: ...
    def __new__(cls, embedding:typing.Sequence[builtins.float], document:builtins.str, metadata:typing.Optional[typing.Mapping[builtins.str, typing.Any]]=None) -> VectorStoreAddInput: ...

class VectorStoreGetResult:
    @property
    def id(self) -> builtins.str: ...
    @property
    def document(self) -> builtins.str: ...
    @property
    def metadata(self) -> typing.Optional[builtins.dict[builtins.str, typing.Any]]: ...
    @property
    def embedding(self) -> builtins.list[builtins.float]: ...
    @id.setter
    def id(self, value: builtins.str) -> None: ...
    @document.setter
    def document(self, value: builtins.str) -> None: ...
    @metadata.setter
    def metadata(self, value: typing.Optional[builtins.dict[builtins.str, typing.Any]]) -> None: ...
    @embedding.setter
    def embedding(self, value: builtins.list[builtins.float]) -> None: ...

class VectorStoreRetrieveResult:
    @property
    def id(self) -> builtins.str: ...
    @property
    def document(self) -> builtins.str: ...
    @property
    def metadata(self) -> typing.Optional[builtins.dict[builtins.str, typing.Any]]: ...
    @property
    def distance(self) -> builtins.float: ...
    @id.setter
    def id(self, value: builtins.str) -> None: ...
    @document.setter
    def document(self, value: builtins.str) -> None: ...
    @metadata.setter
    def metadata(self, value: typing.Optional[builtins.dict[builtins.str, typing.Any]]) -> None: ...
    @distance.setter
    def distance(self, value: builtins.float) -> None: ...

class APISpecification(Enum):
    ChatCompletion = ...
    OpenAI = ...
    Gemini = ...
    Claude = ...
    Responses = ...
    Grok = ...

class FinishReason(Enum):
    r"""
    Explains why a language model's streamed generation finished.
    """
    Stop = ...
    r"""
    The model stopped naturally (e.g., EOS token or stop sequence).
    """
    Length = ...
    r"""
    Hit the maximum token/length limit.
    """
    ToolCall = ...
    r"""
    Stopped because a tool call was produced, waiting for it's execution.
    """
    Refusal = ...
    r"""
    Content was refused/filtered; string provides reason.
    """

    def __repr__(self) -> builtins.str: ...

class Role(Enum):
    r"""
    The author of a message (or streaming delta) in a chat.
    """
    System = ...
    r"""
    System instructions and constraints provided to the assistant.
    """
    User = ...
    r"""
    Content authored by the end user.
    """
    Assistant = ...
    r"""
    Content authored by the assistant/model.
    """
    Tool = ...
    r"""
    Outputs produced by external tools/functions
    """

    def __repr__(self) -> builtins.str: ...

class ThinkEffort(Enum):
    Disable = ...
    Enable = ...
    Low = ...
    Medium = ...
    High = ...
