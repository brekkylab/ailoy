# Devices & Environments

**On-device AI** is one of biggest feature of Ailoy that make it different from
other AI tools.  
To make it feasible, you might need to check the conditions for the devices &
environments to run AIs.

## Supported environments

{/* prettier-ignore-start */}

:::note
To see the lastest details on system requirements, refer to the official repository's **[README.md](https://github.com/brekkylab/ailoy/blob/main/README.md#requirements)**.
:::

{/* prettier-ignore-end */}

- **_macOS_** devices running on Apple Silicon with _Metal_ support
- **_Windows_** PC running on latest x86*64 CPU & GPU with \_Vulkan 1.3* support
- **_Linux_** PC running on latest x86*64 CPU & GPU with \_Vulkan 1.3* support

...and _WebGPU_ and _Mobile devices_ supports are on plan!

### VRAM requirements

{/* prettier-ignore-start */}

:::warning
These values may vary depending on the environment and circumstances.
:::

{/* prettier-ignore-end */}

Requirements for available VRAM size by models are estimated as follows:

| Model                | Context length | VRAM (params) | VRAM (total) |
| -------------------- | :------------: | :-----------: | :----------: |
| `BAAI/bge-m3`        |       8k       |    ≈ 0.3GB    |   ≈ 0.3GB    |
| `Qwen/Qwen3-0.6B`    |      41k       |    ≈ 0.5GB    |   ≈ 5.0GB    |
| `Qwen/Qwen3-1.7B`    |      41k       |    ≈ 1.0GB    |   ≈ 5.5GB    |
| `Qwen/Qwen3-4B`      |      41k       |    ≈ 2.4GB    |   ≈ 8.0GB    |
| `Qwen/Qwen3-8B`      |      41k       |    ≈ 4.5GB    |   ≈ 10.5GB   |
| `Qwen/Qwen3-14B`     |      41k       |   ≈ 8.0 GB    |  ≈ 14.5 GB   |
| `Qwen/Qwen3-32B`     |      41k       |   ≈ 17.6 GB   |   ≈ 25 GB    |
| `Qwen/Qwen3-30B-A3B` |      41k       |   ≈ 16.5 GB   |   ≈ 24 GB    |

## Device selection

In some cases, you may want to exploit Ailoy in an environment with multiple
accelerators, in which case you may want to select the accelerator on which to
run AI.  
e.g.) Running Embedding model and Language model on separate devices in a RAG
application

Each AI model exists as a `component` in Ailoy, and components can be created by
giving them a device ID to load each model onto the corresponding device.  
The default device ID is `0`, which uses the first device in the system.

#### Using Agent & VectorStore

<CodeTabs>

{/* prettier-ignore-start */}

:::info
To see the full context of RAG application example, visit **[RAG with Vector Store](/docs/tutorial/rag-with-vector-store)**.
:::

{/* prettier-ignore-end */}

```python
agent = Agent(runtime, LocalModel("Qwen/Qwen3-8B", device=1))
vs = VectorStore(runtime, "BAAI/bge-m3", "faiss", embedding_model_attrs={"device": 0})

...

agent.delete()
vs.delete()
```

```typescript
const agent = await defineAgent(rt, LocalModel({id: "Qwen/Qwen3-8B", device: 1}));
const vs = await defineVectorStore(rt, "BAAI/bge-m3", "faiss", { device : 0 });

...

await agent.delete()
await vs.delete()
...
```

</CodeTabs>

#### Using Runtime APIs

<CodeTabs>

```python
rt.define("tvm_language_model", "lm0", {"model": "Qwen/Qwen3-8B", "device": 1})
rt.define("tvm_embedding_model", "em0", {"model": "BAAI/bge-m3", "device": 0})
```

```typescript
await rt.define("tvm_language_model", "lm0", {
  model: "Qwen/Qwen3-8B",
  device: 1,
});
await rt.define("tvm_embedding_model", "em0", {
  model: "BAAI/bge-m3",
  device: 0,
});
```

</CodeTabs>
