# Chat Completion Format

Conventionally, in a chat completion setup, both **input** and **output** follow a structured format.
Messages are typically represented as follows:

```
[
  {
    "role": "system",
    "contents": [
      { "type": "text", "text": "You are a friendly and knowledgeable assistant." }
    ]
  },
  {
    "role": "user",
    "contents": [
      { "type": "text", "text": "Can you explain how photosynthesis works?" }
    ]
  }
]
```

When it is executed, the output might look like:
```
{
    "role": "assistant",
    "contents": [
        {
            "type": "text",
            "text": "Photosynthesis is the process by which plants convert sunlight, water, and carbon dioxide into energy. They use sunlight to produce glucose (a form of sugar) and release oxygen as a byproduct."
        }
    ]
}
```


:::info
Please refer to followings for more about this schema.

- [Transformers apply_chat_template](https://huggingface.co/docs/transformers/main/chat_templating)
- [OpenAI chat completion API](https://platform.openai.com/docs/api-reference/chat/create)
:::

## Message

A `Message` represents one conversational turn — what one participant (system, user, or assistant) says or does.

Each message contains:
- a **role**, indicating who is speaking,
- a set of **contents**, describing what was said or sent.

### Role

|Role|Description|
|---|---|
|**System**|System instructions and constraints provided to the assistant. It usually defines the model’s behavior or persona.|
|**User**|Contents authored by the user.|
|**Assistant**|Contents automatically generated by the assistant / AI model.|
|**Tool**|Execution results produced by external tools / functions.|

### Contents

What is said from each role is generally referred to as content.
However, a model can operate in different modes, producing outputs that serve different purposes.

These outputs reflect the **intention** behind what the model says or performs.

|Intent|Description|
|---|---|
|**Content**|General output.|
|**Reasoning(thinking)**|Some model generates intermediate thoughts or reasoning traces before producing the final answer. These are stored in the reasoning field (often hidden from the user) and can help trace or visualize the model’s internal decision process.|
|**Tool call**|When the model decides to invoke an external function or API instead of generating plain text. These are represented as structured objects that describe which function to call(name) and with what arguments.|

These types of outputs are stored in separate fields within a message, making it possible to distinguish from general conversation.

**Example**

```
[
  Message {
      role: "assistant",
      reasoning: "Let’s reason step by step: photosynthesis converts light energy into chemical energy...",
      contents: [
          { type: "text", text: "Photosynthesis is the process by which plants convert sunlight, water, and carbon dioxide into energy." }
      ],
      tool_calls: [
          {
            type: "function",
            function: {
              id: "func_call_1234abcd",
              name: "get_current_location",
              arguments: ...
            }
          }
      ],
  },
]
```

### Part

While `Contents` describe the intention of a message, `Part` defines the **data type** of that message.

`Part` can be considered as a smallest semantic units within a conversation.
Each `Message` contains a list of `Part` objects.
A `Part` can represent text, images, function calls, or any structured values, enabling rich multimodal communication.

|Part|Description|
|---|---|
|**Text**|Natural-language text content|
|**Image**|Visual data or reference (e.g., binary, URL, or metadata)|
|**Function**|Structured tool or function invocation|
|**Value**|Arbitrary data (numbers, objects, JSON values, etc.)|

For example, if a user asks about an image, the message could look like this:

```
contents: [
  {type: "image", "image": {data: "..."}}
  {type: "text", text: "What you can see in this image?"} 
]
```

Together, these parts express Ailoy’s multimodal conversation.

### Delta

The inference of a language model can take a significant amount of time.
To improve real-time responsiveness, many AI systems stream tokens as they are generated.
These streamed outputs are typically delivered in the form of **deltas**.

A **delta**(`MessageDelta` or `PartDelta`) represents an output of this step(inference) updated during a streaming response.
As the model generates text token by token, each incremental addition is emitted as a delta, which is later merged into a complete `Message`.

Ailoy provides a simple way to retrieve and aggregate deltas.
One can use `accumulate` and `finish` function.

<CodeTabs>

```python
import ailoy as ai

...
accumulated = new ai.MessageDelta();
async for output in agent.run_delta([query]):
    accumulated += output.delta
accumulated = accumulated.finish()    
```

```typescript
import { MessageDelta } from "ailoy";

...
let accumulated = MessageDelta();
for await (const resp of agent.run([query])) {
    accumulated.accumulate(resp.delta);
}
accumulated = accumulated.finish();
```

</CodeTabs>

## Tool

A Tool enables the model to act — to execute external functions, access APIs, or perform any operation beyond plain text generation.

Each tool has two halves:
- Description (declarative) — defines what the tool is and how it can be called.
- Behavior (imperative) — defines what your code actually does when the tool is invoked.

Together, they allow the model to dynamically invoke external capabilities while keeping reasoning and execution logically separated.

:::info
Please refer to following resources for more about the tool schema convention.

- [Transformers tool_use](https://huggingface.co/docs/transformers/main/chat_extras)
- [OpenAI chat completion API](https://platform.openai.com/docs/api-reference/chat/create#chat-create-tool_choice-function-tool-choice)
- [MCP](https://modelcontextprotocol.io/specification/2025-06-18/server/tools#data-types)
:::

### Tool Description

Ailoy follows a JSON-Schema-like convention to describe tool arguments and optional return schemas.
This ensures that language models can reliably construct valid function calls — the schema precisely defines the allowed parameters, required fields, and expected return structure.

```
{
  "name": "get_weather",
  "description": "Retrieve current weather data for a specific city.",
  "parameters": {
    "type": "object",
    "required": ["city"],
    "properties": {
      "city": { "type": "string", "description": "City name" },
      "unit": { "type": "string", "enum": ["c", "f"], "default": "c" }
    },
    "additionalProperties": false
  },
  "returns": {
    "type": "object",
    "properties": {
      "temp": { "type": "number" },
      "condition": { "type": "string" }
    },
    "required": ["temp", "condition"]
  }
}
```

### Tool Call

When a model decides to use a tool instead of generating plain text, it emits a tool call.
This occurs inside an assistant message — since the assistant is the one deciding to call a tool — but the call is placed inside the tool_calls field (not contents).

A typical tool call message looks like this:

```
{
  "role": "assistant",
  "contents": [
    { "type": "text", "text": "Let me check the current weather for you." }
  ],
  "tool_calls": [
    {
      "type": "function",
      "function": {
        "name": "get_weather",
        "arguments": { "city": "Seoul", "unit": "c" }
      },
      "id": "call_01HZX2..."
    }
  ]
}
```

Explanation:
- The assistant outputs a structured tool call in `tool_calls` segment.
- The runtime then executes the corresponding function based on its name and arguments.
- The `id` field can optionally be tagged, which uniquely identifies this tool call, allowing the tool’s response to be correctly linked.

### Tool Response

Once the runtime executes the tool’s behavior, it must append a new message to the conversation, with the role set to "tool".
Also, the result is stored inside the `contents` field.

For example

```
{
  "role": "tool",
  "tool_call_id": "call_01HZX2...",
  "name": "get_weather",
  "contents": [
    { "type": "value", "value": { "temp": 12.3, "condition": "cloudy" } }
  ]
}
```

When an error occurs in a tool, it should still be passed along so that the model can recognize and handle it.

```
{
  "role": "tool",
  "tool_call_id": "call_01HZX2...",
  "name": "get_weather",
  "contents": [
    { "type": "value", "value": { "error": { "code": "NOT_FOUND", "message": "Unknown city" } } }
  ]
}
```

## Document
