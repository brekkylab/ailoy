# Multi-Turn Conversation

Ailoy's `Agent` is designed to be stateless. It does not keep track of
conversation histories. Each time you call the model, agent treats it as a new
request.

If you want to create a multi-turn chat — for example, a back-and-forth
conversation with the assistant — you must include the entire conversation
history (all previous messages) in the request.

Let's see it step by step.

{/* prettier-ignore-start */}

:::info 
Just want to see a completed example? Check out the **[last example](#example-of-ongoing-conversations)**!
:::

{/* prettier-ignore-end */}

## Step-by-step guide

Let’s start with a single-turn conversation:

{/* prettier-ignore-start */}

<CodeTabs>

```python
import asyncio

import ailoy as ai


async def main():
    lm = await ai.LangModel.new_local("Qwen/Qwen3-0.6B")
    agent = ai.Agent(lm)

    messages = [ai.Message(role="user", contents="Hello!")]
    async for resp in agent.run(messages):
        if isinstance(resp.message.contents[0], ai.Part.Text):
            print(resp.message.contents[0].text)


if __name__ == "__main__":
    asyncio.run(main())
```

```typescript
import * as ai from "ailoy-node";

(async () => {
  const model = await ai.LangModel.newLocal("Qwen/Qwen3-0.6B");
  const agent = new ai.Agent(model);

  const messages = [
    { role: "user", contents: "Hello!" },
  ] as ai.Messages;
  for await (const resp of agent.run(messages)) {
    console.log(resp.contents[0].text);
  }
})();
```

```typescript web
import * as ai from "ailoy-web";

(async () => {
  const model = await ai.LangModel.newLocal("Qwen/Qwen3-0.6B");
  const agent = new ai.Agent(model);

  const messages = [
    { role: "user", contents: "Hello!" },
  ] as ai.Messages;
  for await (const resp of agent.run(messages)) {
    console.log(resp.contents[0].text);
  }
})();
```

</CodeTabs>

{/* prettier-ignore-end */}

The model will respond to your "Hello!" message.  
Let's say it responds like this:

```
Hi there! How can I help you today?
```

Now, to continue the conversation, you must pass _both_ the **previous
messages** and **your new user message** again:

{/* prettier-ignore-start */}

<CodeTabs>

```python
import asyncio

import ailoy as ai


async def main():
    lm = await ai.LangModel.new_local("Qwen/Qwen3-0.6B")
    agent = ai.Agent(lm)

    messages = [
        # the previous messages
        ai.Message(role="user", contents="Hello!"),
        ai.Message(role="assistant", contents="Hi there! How can I help you today?"),
        # your new user message
        ai.Message(role="user", contents="What did I just say?"),
    ]
    async for resp in agent.run(messages):
        if isinstance(resp.message.contents[0], ai.Part.Text):
            print(resp.message.contents[0].text)

if __name__ == "__main__":
    asyncio.run(main())
```

```typescript
import * as ai from "ailoy-node";

(async () => {
  const model = await ai.LangModel.newLocal("Qwen/Qwen3-0.6B");
  const agent = new ai.Agent(model);

  const messages = [
    // the previous messages
    { role: "user", contents: "Hello!" },
    { role: "assistant", contents: "Hi there! How can I help you today?" },
    // your new user message
    { role: "user", contents: "What did I just say?" },
  ]
  for await (const resp of agent.run(messages)) {
    console.log(resp.contents[0].text);
  }
})();
```

```typescript web
import * as ai from "ailoy-web";

(async () => {
  const model = await ai.LangModel.newLocal("Qwen/Qwen3-0.6B");
  const agent = new ai.Agent(model);

  const messages = [
    // the previous messages
    { role: "user", contents: "Hello!" },
    { role: "assistant", contents: "Hi there! How can I help you today?" },
    // your new user message
    { role: "user", contents: "What did I just say?" },
  ]
  for await (const resp of agent.run(messages)) {
    console.log(resp.contents[0].text);
  }
})();
```

</CodeTabs>

{/* prettier-ignore-end */}

Ailoy will now use the full conversation context to produce the correct reply —
even though it doesn’t persist any state internally.

Here, I want to make the conversation continue by itself.  
Let's consider a user who always speaks the specified words in a fixed order.

We will use a loop to add user messages and get the agent's responses one by
one.

{/* prettier-ignore-start */}

<CodeTabs>

```python
import asyncio

import ailoy as ai


async def main():
    lm = await ai.LangModel.new_local("Qwen/Qwen3-0.6B")
    agent = ai.Agent(lm)

    USER_MESSAGES = [
        ai.Message(role="user", contents="Hello!"),
        ai.Message(role="user", contents="What did I just say?"),
        ai.Message(role="user", contents="Oh, you are listening to me carefully!"),
    ]

    messages = []
    for user_message in USER_MESSAGES:
        print("User:", user_message.contents[0].text)
        messages.append(user_message)  # Add user message
        async for resp in agent.run(messages):
            if isinstance(resp.message.contents[0], ai.Part.Text):
                print("Assistant:", resp.message.contents[0].text)
            messages.append(resp.message)  # Add assistant message


if __name__ == "__main__":
    asyncio.run(main())
```

```typescript
import * as ai from "ailoy-node";

(async () => {
  const model = await ai.LangModel.newLocal("Qwen/Qwen3-0.6B");
  const agent = new ai.Agent(model);

  const USER_MESSAGES = [
    { role: "user", contents: "Hello!" },
    { role: "user", contents: "What did I just say?" },
    { role: "user", contents: "Oh, you are listening to me carefully!" },
  ];

  let messages = [];
  for (const user_message of USER_MESSAGES) {
    messages.push(user_message);
    for await (const resp of agent.run(messages as ai.Messages)) {
      if (resp.message.contents[0].type == "text")
        console.log(resp.message.contents[0].text);
      messages.push(resp.message);
    }
  }
})();
```

```typescript web
import * as ai from "ailoy-web";

(async () => {
  const model = await ai.LangModel.newLocal("Qwen/Qwen3-0.6B");
  const agent = new ai.Agent(model);

  const USER_MESSAGES = [
    { role: "user", contents: "Hello!" },
    { role: "user", contents: "What did I just say?" },
    { role: "user", contents: "Oh, you are listening to me carefully!" },
  ];

  let messages = [];
  for (const user_message of USER_MESSAGES) {
    messages.push(user_message);
    for await (const resp of agent.run(messages as ai.Messages)) {
      if (resp.message.contents[0].type == "text")
        console.log(resp.message.contents[0].text);
      messages.push(resp.message);
    }
  }
})();
```

</CodeTabs>

{/* prettier-ignore-end */}

Now we just can replace the fixed inputs with live user inputs to make it real
conversation!

## Example of ongoing conversations

The code below is an example of receiving real-time input from the user and
continuing a conversation with the agent.

{/* prettier-ignore-start */}

<CodeTabs>

```python
import asyncio

import ailoy as ai


async def main():
    lm = await ai.LangModel.new_local("Qwen/Qwen3-0.6B")
    agent = ai.Agent(lm)

    print("(Enter 'exit' to end the conversation.)")
    messages = []
    while (user_message := input("User: ")).lower() != "exit":
        messages.append(ai.Message(role="user", contents=user_message))
        async for resp in agent.run(messages):
            if isinstance(resp.message.contents[0], ai.Part.Text):
                print("Assistant:", resp.message.contents[0].text)
            messages.append(resp.message)
    print("Assistant: It was a nice conversation!")


if __name__ == "__main__":
    asyncio.run(main())
```

```typescript
import * as ai from "ailoy-node";
import * as readline from "readline";

(async () => {
  const model = await ai.LangModel.newLocal("Qwen/Qwen3-0.6B");
  const agent = new ai.Agent(model);
  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout,
  });

  const question = (msg: string) =>
    new Promise<string>((res) => rl.question(msg, res));
  let messages: ai.Messages = [];

  console.log("(Enter 'exit' to end the conversation.)");

  while (true) {
    const input = (await question("User: ")).trim();
    if (input.toLowerCase() === "exit") break;

    messages.push({ role: "user", contents: input });

    for await (const resp of agent.run(messages as ai.Messages)) {
      if (resp.message.contents[0].type === "text")
        console.log("Assistant:", resp.message.contents[0].text);
      messages.push(resp.message);
    }
  }

  console.log("Assistant: It was a nice conversation!");
  rl.close();
})();
```

</CodeTabs>

{/* prettier-ignore-end */}
