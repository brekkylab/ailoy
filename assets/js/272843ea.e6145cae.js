"use strict";(self.webpackChunkailoy_docs=self.webpackChunkailoy_docs||[]).push([[7893],{3283:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>h,frontMatter:()=>r,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"tutorial/thinking","title":"Thinking","description":"Thinking (or reasoning) is an advanced capability of AI that enables it to","source":"@site/docs/tutorial/thinking.mdx","sourceDirName":"tutorial","slug":"/tutorial/thinking","permalink":"/ailoy/docs/tutorial/thinking","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"documentSidebar","previous":{"title":"Streaming","permalink":"/ailoy/docs/tutorial/streaming"},"next":{"title":"Using Tools","permalink":"/ailoy/docs/tutorial/using-tools"}}');var s=i(4848),o=i(8453);const r={},l="Thinking",a={},d=[{value:"Hybrid Thinking Models",id:"hybrid-thinking-models",level:2},{value:"How to Enable Thinking",id:"how-to-enable-thinking",level:3},{value:"Adjusting Thinking Effort",id:"adjusting-thinking-effort",level:2}];function c(e){const n={a:"a",admonition:"admonition",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components},{TabItem:i,Tabs:t}=n;return i||p("TabItem",!0),t||p("Tabs",!0),(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"thinking",children:"Thinking"})}),"\n",(0,s.jsx)(n.p,{children:"Thinking (or reasoning) is an advanced capability of AI that enables it to\ntackle complex tasks through explicit, step-by-step logical inference. Thinking\nmodels break down problems into smaller reasoning steps rather than solving them\nin a single pass. Compared to direct answer generation, it offers two key\nadvantages:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Improved problem-solving capability"}),"\n",(0,s.jsx)(n.li,{children:"Transparent and traceable intermediate thinking steps"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"This functionality is particularly well-suited for domains that require\nmulti-step thinking, such as scientific analysis, legal interpretation, or\nstrategic decision-making. However, since the thinking step requires additional\ncomputation and memory usage, it can increase latency and overall resource\nconsumption. Therefore, it\u2019s important to use thinking only when necessary,\nbased on the complexity of your use case."}),"\n",(0,s.jsx)(n.admonition,{type:"info",children:(0,s.jsxs)(n.p,{children:["Small models like ",(0,s.jsx)(n.code,{children:"Qwen3-0.6B"})," are generally too limited to perform effective\nreasoning.",(0,s.jsx)(n.br,{}),"\n","For complex tasks, we recommend using a sufficiently large model."]})}),"\n",(0,s.jsx)(n.h2,{id:"hybrid-thinking-models",children:"Hybrid Thinking Models"}),"\n",(0,s.jsx)(n.p,{children:"Some modern models, such as Qwen3, are designed as hybrid thinking models. These\nmodels can switch between standard (direct-generation) and thinking modes based\non configuration settings."}),"\n",(0,s.jsx)(n.p,{children:"Ailoy fully supports this hybrid capability. You can explicitly turn the\nthinking process on or off via the thinking option. When enabled, the model\nengages in structured, step-by-step inference\u2014producing a detailed \u201cthinking\ntrace\u201d before the final answer."}),"\n",(0,s.jsx)(n.h3,{id:"how-to-enable-thinking",children:"How to Enable Thinking"}),"\n",(0,s.jsxs)(n.p,{children:["To enable thinking, simply specify the ",(0,s.jsx)(n.code,{children:"think_effort"})," in the inference config\nwhen running the agent.",(0,s.jsx)(n.br,{}),"\n","If you pass the inference config under the ",(0,s.jsx)(n.code,{children:"inference"})," key within the agent\nconfig, it will be passed to the internal ",(0,s.jsx)(n.code,{children:"LangModel"}),"."]}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsxs)(n.p,{children:["If you enable thinking, the time required to generate an entire message can\nincrease quite a lot, which makes your application look less responsive, so it\nmay be better to run the agent with ",(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/docs/tutorial/streaming",children:"streaming"})}),"."]})}),"\n",(0,s.jsxs)(t,{groupId:"code-language",children:[(0,s.jsx)(i,{value:"python",label:"Python",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",metastring:"showLineNumbers",children:'import asyncio\n\nimport ailoy as ai\n\n\nasync def main():\n    lm = await ai.LangModel.new_local("Qwen/Qwen3-4B")\n    agent = ai.Agent(lm)\n\n    GREEN = "\\x1b[32m"\n    RESET = "\\x1b[0m"\n\n    async for resp in agent.run_delta(\n        "Please solve me a simultaneous equation: x+y=3, 4x+3y=12",\n        config=ai.AgentConfig(inference=ai.InferenceConfig(think_effort="enable")),\n    ):\n        if resp.delta.thinking:\n            # thinking text will be printed in green.\n            print(GREEN + resp.delta.thinking + RESET, end="")\n        if resp.delta.contents and isinstance(\n            resp.delta.contents[0], ai.PartDelta.Text\n        ):\n            print(resp.delta.contents[0].text, end="")\n\n\nif __name__ == "__main__":\n    asyncio.run(main())\n'})})}),(0,s.jsx)(i,{value:"javascript",label:"JavaScript",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",metastring:"showLineNumbers",children:'import * as ai from "ailoy-node";\n\nasync function main() {\n  const lm = await ai.LangModel.newLocal("Qwen/Qwen3-4B");\n  const agent = new ai.Agent(lm);\n\n  const GREEN = "\\x1b[32m";\n  const RESET = "\\x1b[0m";\n\n  for await (const resp of agent.runDelta(\n    "Please solve me a simultaneous equation: x+y=3, 4x+3y=12",\n    { inference: { thinkEffort: "enable" } }\n  )) {\n    if (resp.delta.thinking !== undefined) {\n      // thinking text will be printed in green.\n      process.stdout.write(GREEN + resp.delta.thinking + RESET);\n    }\n    if (\n      resp.delta.contents.length !== 0 &&\n      resp.delta.contents[0].type === "text"\n    ) {\n      process.stdout.write(resp.delta.contents[0].text);\n    }\n  }\n}\n\nmain().catch((err) => {\n  console.error("Error:", err);\n});\n'})})}),(0,s.jsx)(i,{value:"web",label:"JavaScript(Web)",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",metastring:"web showLineNumbers",children:'import * as ai from "ailoy-web";\n\nasync function main() {\n  const lm = await ai.LangModel.newLocal(\n    "Qwen/Qwen3-4B",\n    undefined,\n    console.log\n  );\n  const agent = new ai.Agent(lm);\n\n  const GREEN = "\\x1b[32m";\n  const RESET = "\\x1b[0m";\n\n  for await (const resp of agent.runDelta(\n    "Please solve me a simultaneous equation: x+y=3, 4x+3y=12",\n    { inference: { thinkEffort: "enable" } }\n  )) {\n    if (resp.delta.thinking !== undefined) {\n      // thinking text will be printed in green.\n      console.log(GREEN + resp.delta.thinking + RESET);\n    }\n    if (\n      resp.delta.contents.length !== 0 &&\n      resp.delta.contents[0].type === "text"\n    ) {\n      console.log(resp.delta.contents[0].text);\n    }\n  }\n}\n\nmain().catch((err) => {\n  console.error("Error:", err);\n});\n'})})})]}),"\n",(0,s.jsx)(n.h2,{id:"adjusting-thinking-effort",children:"Adjusting Thinking Effort"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"think_effort"})," option determines ",(0,s.jsx)(n.strong,{children:"how much reasoning power the model uses"}),"\nbefore giving an answer. Increasing this value enhances logical and systematic\nthinking, but also consumes more time and resources. You can think of it as a\nbalance between ",(0,s.jsx)(n.strong,{children:"intelligence"})," and ",(0,s.jsx)(n.strong,{children:"budget or responsiveness"}),":"]}),"\n",(0,s.jsx)(n.p,{children:"In short:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Higher ",(0,s.jsx)(n.code,{children:"think_effort"})," \u2192 smarter but slower."]}),"\n",(0,s.jsxs)(n.li,{children:["Lower ",(0,s.jsx)(n.code,{children:"think_effort"})," \u2192 faster but shallower."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"think_effort"})," can have one of these in the config:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:'"disable"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:'"enable"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:'"low"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:'"medium"'})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:'"high"'})}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["But not all models are hybrid thinking models or capable of fine-grained\nadjustment of thinking effort.",(0,s.jsx)(n.br,{}),"\n","Therefore, depending on the characteristics of the model, ",(0,s.jsx)(n.code,{children:"think_effort"})," may\nactually be applied differently from the specified value without explicit\nwarning."]}),"\n",(0,s.jsx)(n.p,{children:"For example,"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["OpenAI's ",(0,s.jsx)(n.code,{children:"gpt-4"})," model does not support thinking, so it will be applied as\n",(0,s.jsx)(n.code,{children:'"disable"'})," regardless of which value is applied."]}),"\n",(0,s.jsxs)(n.li,{children:["OpenAI's ",(0,s.jsx)(n.code,{children:"o4"})," model supports ",(0,s.jsx)(n.code,{children:'"low"'}),", ",(0,s.jsx)(n.code,{children:'"medium"'}),", ",(0,s.jsx)(n.code,{children:'"high"'})," but not\n",(0,s.jsx)(n.code,{children:'"disable"'}),', so if "disable" is specified, it will be applied as ',(0,s.jsx)(n.code,{children:'"low"'}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["The ",(0,s.jsx)(n.code,{children:"grok-4-fast"})," model only supports ",(0,s.jsx)(n.code,{children:'"low"'})," or ",(0,s.jsx)(n.code,{children:'"high"'}),", so if ",(0,s.jsx)(n.code,{children:'"medium"'})," is\nspecified, it will be applied as ",(0,s.jsx)(n.code,{children:'"low"'}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["All Qwen3 models do not support adjusting ",(0,s.jsx)(n.code,{children:"think_effort"}),", so any value other\nthan ",(0,s.jsx)(n.code,{children:'"disable"'})," will be equivalent to ",(0,s.jsx)(n.code,{children:'"enable"'}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"think_effort"})," is applied as the most similar one to what the user specified\nwithin the supported range, but you'd better to check the model specification\nfor predictable model behavior."]})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}function p(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}}}]);