"use strict";(self.webpackChunkailoy_docs=self.webpackChunkailoy_docs||[]).push([[5776],{5474:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>p,frontMatter:()=>s,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"tutorial/mcp-integration","title":"MCP Integration","description":"The Model Context Protocol (MCP) is an open protocol developed by Anthropic","source":"@site/docs/tutorial/mcp-integration.mdx","sourceDirName":"tutorial","slug":"/tutorial/mcp-integration","permalink":"/ailoy/docs/tutorial/mcp-integration","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"documentSidebar","previous":{"title":"Using Tools","permalink":"/ailoy/docs/tutorial/using-tools"},"next":{"title":"RAG Using Documents","permalink":"/ailoy/docs/tutorial/rag-using-documents"}}');var i=t(4848),a=t(8453);const s={},r="MCP Integration",l={},c=[{value:"Step-by-Step Guide",id:"step-by-step-guide",level:2},{value:"Loading MCP Clients",id:"loading-mcp-clients",level:3},{value:"Extracting MCP Tools",id:"extracting-mcp-tools",level:3},{value:"Registering Tools into Agent",id:"registering-tools-into-agent",level:3},{value:"Querying via MCP Tools",id:"querying-via-mcp-tools",level:3},{value:"Complete Example",id:"complete-example",level:2},{value:"Output",id:"output",level:2}];function d(e){const n={a:"a",admonition:"admonition",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",p:"p",pre:"pre",strong:"strong",...(0,a.R)(),...e.components},{TabItem:t,Tabs:o,TerminalBox:s}=n;return t||h("TabItem",!0),o||h("Tabs",!0),s||h("TerminalBox",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"mcp-integration",children:"MCP Integration"})}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.strong,{children:"Model Context Protocol (MCP)"})," is an open protocol developed by Anthropic\nto standardize how language models interact with external systems\u2014such as tools,\nmemory backends, and context managers. MCP enables structured, dynamic\ncommunication between an LLM and its environment, empowering models to access\nexternal tools, retrieve real-time information, and perform complex, multi-step\nreasoning."]}),"\n",(0,i.jsxs)(n.admonition,{type:"info",children:[(0,i.jsxs)(n.p,{children:["Standard input/output is not available in the web environment. Therefore, only\nthe MCP tools based on streamable HTTP are available in the web environment.",(0,i.jsx)(n.br,{}),"\n","For information on MCP integration in the web environment, please refer to the\n",(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"webassembly-supports#using-mcp-tools",children:"WebAssembly Supports"})}),"."]}),(0,i.jsx)(n.p,{children:"The following examples demonstrate MCP tools that use standard input/output only\nin a native environment."})]}),"\n",(0,i.jsx)(n.h2,{id:"step-by-step-guide",children:"Step-by-Step Guide"}),"\n",(0,i.jsx)(n.h3,{id:"loading-mcp-clients",children:"Loading MCP Clients"}),"\n",(0,i.jsx)(n.p,{children:"You can connect to any MCP server using the MCPClient interface. For example,\nthe snippet below connects to the official GitHub MCP server."}),"\n",(0,i.jsxs)(o,{groupId:"code-language",children:[(0,i.jsx)(t,{value:"python",label:"Python",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",metastring:"showLineNumbers",children:'client = await ai.MCPClient.from_stdio(\n    "npx", ["-y", "@modelcontextprotocol/server-github"]\n)\n'})})}),(0,i.jsx)(t,{value:"javascript",label:"JavaScript",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",metastring:"showLineNumbers",children:'const client = await ai.MCPClient.newStdio("npx", [\n  "-y",\n  "@modelcontextprotocol/server-github",\n]);\n'})})})]}),"\n",(0,i.jsx)(n.p,{children:"This launches the GitHub MCP server as a subprocess using standard I/O for\ncommunication. The agent automatically discovers the tools exposed by the server\nand registers them to its internal toolset."}),"\n",(0,i.jsx)(n.h3,{id:"extracting-mcp-tools",children:"Extracting MCP Tools"}),"\n",(0,i.jsx)(n.p,{children:"Each MCP server can expose multiple tools. To optimize context usage, you can\nselectively extract a subset of tools rather than registering all of them."}),"\n",(0,i.jsxs)(o,{groupId:"code-language",children:[(0,i.jsx)(t,{value:"python",label:"Python",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",metastring:"showLineNumbers",children:'tools = [\n    client.get_tool("search_repositories"),\n    client.get_tool("get_file_contents"),\n]\n'})})}),(0,i.jsx)(t,{value:"javascript",label:"JavaScript",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",metastring:"showLineNumbers",children:'const tools = [\n  client.getTool("search_repositories"),\n  client.getTool("get_file_contents"),\n];\n'})})})]}),"\n",(0,i.jsx)(n.h3,{id:"registering-tools-into-agent",children:"Registering Tools into Agent"}),"\n",(0,i.jsxs)(n.p,{children:["To integrate MCP tools with LM, they must be registered to ",(0,i.jsx)(n.code,{children:"Agent"}),".",(0,i.jsx)(n.br,{}),"\n","Once registered, the agent can automatically invoke these tools during reasoning\nor when responding to user queries."]}),"\n",(0,i.jsxs)(o,{groupId:"code-language",children:[(0,i.jsx)(t,{value:"python",label:"Python",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",metastring:"showLineNumbers",children:'lm = await ai.LangModel.new_local("Qwen/Qwen3-8B", progress_callback=print)\nagent = ai.Agent(lm, tools)\n'})})}),(0,i.jsx)(t,{value:"typescrpt",label:"Typescrpt",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescrpt",metastring:"showLineNumbers",children:'const lm = await ai.LangModel.newLocal("Qwen/Qwen3-8B", null, console.log);\nconst agent = new ai.Agent(lm, tools);\n'})})})]}),"\n",(0,i.jsx)(n.h3,{id:"querying-via-mcp-tools",children:"Querying via MCP Tools"}),"\n",(0,i.jsxs)(n.p,{children:["With tools registered, the agent can automatically use them when you invoke\n",(0,i.jsx)(n.code,{children:"run()"})," or ",(0,i.jsx)(n.code,{children:"run_delta()"}),"."]}),"\n",(0,i.jsxs)(o,{groupId:"code-language",children:[(0,i.jsx)(t,{value:"python",label:"Python",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",metastring:"showLineNumbers",children:'question = "Search the repository named brekkylab/ailoy and describe what it does based on its README.md."\nasync for resp in agent.run(question):\n    agent.print(resp)\n'})})}),(0,i.jsx)(t,{value:"javascript",label:"JavaScript",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",metastring:"showLineNumbers",children:'const question =\n  "Search the repository named brekkylab/ailoy and describe what it does based on its README.md.";\nfor await (const resp of agent.run(question)) {\n  agent.print(resp);\n}\n'})})})]}),"\n",(0,i.jsx)(n.p,{children:"This demonstrates how the agent leverages the GitHub MCP tools to search\nrepositories and summarize their contents."}),"\n",(0,i.jsx)(n.h2,{id:"complete-example",children:"Complete Example"}),"\n",(0,i.jsx)(n.p,{children:"The following end-to-end example demonstrates how to set up an agent, connect to\nthe GitHub MCP server, and issue a query."}),"\n",(0,i.jsxs)(o,{groupId:"code-language",children:[(0,i.jsx)(t,{value:"python",label:"Python",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",metastring:"showLineNumbers",children:'import asyncio\n\nimport ailoy as ai\n\n\nasync def main():\n    client = await ai.MCPClient.from_stdio(\n        "npx", ["-y", "@modelcontextprotocol/server-github"]\n    )\n    tools = [\n        client.get_tool("search_repositories"),\n        client.get_tool("get_file_contents"),\n    ]\n    lm = await ai.LangModel.new_local("Qwen/Qwen3-4B", progress_callback=print)\n    agent = ai.Agent(lm, tools)\n    query = "Search the repository named brekkylab/ailoy and describe what it does based on its README.md."\n    async for resp in agent.run(query):\n        print(resp)\n\n\nif __name__ == "__main__":\n    asyncio.run(main())\n'})})}),(0,i.jsx)(t,{value:"javascript",label:"JavaScript",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",metastring:"showLineNumbers",children:'import * as ai from "ailoy-node";\n\nasync function main() {\n  const client = await ai.MCPClient.newStdio("npx", [\n    "-y",\n    "@modelcontextprotocol/server-github",\n  ]);\n  const tools = [\n    client.getTool("search_repositories"),\n    client.getTool("get_file_contents"),\n  ];\n  const lm = await ai.LangModel.newLocal("Qwen/Qwen3-4B", null, console.log);\n  const agent = new ai.Agent(lm, tools);\n  const query =\n    "Search the repository named brekkylab/ailoy and describe what it does based on its README.md.";\n  for await (const resp of agent.run(query)) {\n    console.log(resp.message);\n  }\n}\n\nmain().catch((err) => {\n  console.error("Error:", err);\n});\n'})})})]}),"\n",(0,i.jsx)(n.h2,{id:"output",children:"Output"}),"\n","\n",(0,i.jsx)(s,{children:'\n\u256d\u2500 Tool Call: github-get_file_contents \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 {                                                                    \u2502\n\u2502   "repo": "ailoy",                                                   \u2502\n\u2502   "path": "README.md",                                               \u2502\n\u2502   "owner": "brekkylab",                                              \u2502\n\u2502   "branch": "feature/add-qwen3-big-models"                           \u2502\n\u2502 }                                                                    \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 Tool Result \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 [                                                                    \u2502\n\u2502   "{\\"name\\": \\"README.md\\", \\"path\\": \\"README.md\\", \\"sha\\":       \u2502\n\u2502 \\"563dde166b65319e7614b81a9d8330eee06537d3\\", \\"size\\": 4443,        \u2502\n\u2502 \\"url\\":                                                             \u2502\n\u2502 \\"https://api.github.com/repos/brekkylab/ailoy/contents/README.md?re \u2502\n\u2502 f=feature/add-qwen3-big-models\\", \\"html_url\\":                      \u2502\n\u2502 \\"https://github.com/brekkylab/ailoy/blob/feature/add-qwen3-big-mode \u2502\n\u2502 ls/README.md\\", \\"git_url\\":                                         \u2502\n\u2502 \\"https://api.github.com/repos/brekkylab/ailoy/git/blobs/563dde166b6 \u2502\n\u2502 5319e7614b81a9d8330eee06537d3\\", \\"download_url\\":                   \u2502\n\u2502 \\"https://raw.githubusercontent....(truncated)                       \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nThe repository **brekkylab/ailoy** is a **lightweight library** for building AI applications, such as **agent systems** or **RAG (Retrieval-Augmented Generation) pipelines**. It is designed to simplify the integration and usage of AI models, allowing developers to import and use AI capabilities with minimal effort.\n\n### Key Features:\n- **Support for Local and Cloud AI Models**: It enables the use of local AI models (e.g., Qwen3 variants) and cloud APIs (e.g., OpenAI, Gemini, Claude).\n- **Multi-turn Conversations**: Supports conversational agents with customizable system messages.\n- **Reasoning and Tool Calling**: Facilitates reasoning-based workflows and integration with tools (including `MCP`).\n- **Vector Store Support**: Built-in integration with vector databases like `Faiss` and `ChromaDB`.\n- **Cross-Platform Compatibility**: Works on Windows, macOS (Apple Silicon), and Linux, with specific hardware requirements for local model execution.\n\n### Supported Models:\n- **Local Language Models**: Qwen3 variants (0.6B, 1.7B, 4B, 8B, 14B, 32B, 30B-A3B).\n- **Cloud Models**: OpenAI, Gemini, and Claude.\n- **Embedding Models**: BAAI/bge-m3.\n\n### Use Cases:\n- **Chatbots**: Build simple or advanced chatbots with local or cloud models.\n- **RAG Pipelines**: Combine retrieval and generation for enhanced AI applications.\n- **Custom AI Agents**: Create agents with reasoning capabilities and tool integration.\n\n### Requirements:\n- **Hardware**: At least 8GB of GPU memory is recommended for most models, with higher requirements for larger models like Qwen3-8B (12GB).\n- **OS**: Windows, macOS (Apple Silicon), or Linux with specific versions and drivers.\n\n### Getting Started:\n- **Node.js**: Install via `npm install ailoy-node` and use TypeScript examples.\n- **Python**: Install via `pip install ailoy-py` and use Python examples.\n\nThis repository is in an **early development stage**, and APIs may change. For more details, refer to the [official documentation](https://brekkylab.github.io/ailoy/).\n'}),"\n"]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}function h(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}}}]);