"use strict";(self.webpackChunkailoy_docs=self.webpackChunkailoy_docs||[]).push([[1740],{4462:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>m,frontMatter:()=>o,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"tutorial/image-inputs","title":"Image Inputs","description":"Ailoy supports multi-modal inputs, allowing you to include both text and","source":"@site/docs/tutorial/image-inputs.mdx","sourceDirName":"tutorial","slug":"/tutorial/image-inputs","permalink":"/ailoy/docs/tutorial/image-inputs","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"documentSidebar","previous":{"title":"Multi-Turn Conversation","permalink":"/ailoy/docs/tutorial/multi-turn-conversation"},"next":{"title":"Streaming","permalink":"/ailoy/docs/tutorial/streaming"}}');var i=a(4848),s=a(8453);const o={},r="Image Inputs",l={},d=[{value:"Feeding an Image URL",id:"feeding-an-image-url",level:2},{value:"Feeding an Image File",id:"feeding-an-image-file",level:2}];function c(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",strong:"strong",...(0,s.R)(),...e.components},{TabItem:a,Tabs:t,TerminalBox:o}=n;return a||g("TabItem",!0),t||g("Tabs",!0),o||g("TerminalBox",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"image-inputs",children:"Image Inputs"})}),"\n",(0,i.jsxs)(n.p,{children:["Ailoy supports ",(0,i.jsx)(n.strong,{children:"multi-modal inputs"}),", allowing you to include both text and\nimages in a single message. This enables richer interactions such as visual\nquestion answering, image captioning, and grounded reasoning."]}),"\n",(0,i.jsx)(n.admonition,{type:"info",children:(0,i.jsx)(n.p,{children:"Image input is currently supported only for API-based models that natively\nunderstand visual content."})}),"\n",(0,i.jsx)(n.p,{children:"We will use an image of a golden retriever in the following examples."}),"\n",(0,i.jsx)("img",{src:"https://upload.wikimedia.org/wikipedia/commons/b/bd/Golden_Retriever_Dukedestiny01_drvd.jpg",width:"50%"}),"\n",(0,i.jsx)(n.h2,{id:"feeding-an-image-url",children:"Feeding an Image URL"}),"\n",(0,i.jsxs)(n.p,{children:["You can provide image inputs as multiple parts within a single message. For\nexample, you can attach an image via URL using the ",(0,i.jsx)(n.code,{children:"image_from_url"})," method\ntogether with text parts inside a Message object."]}),"\n",(0,i.jsxs)(t,{groupId:"code-language",children:[(0,i.jsx)(a,{value:"python",label:"Python",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",metastring:"showLineNumbers",children:'import asyncio\n\nimport ailoy as ai\n\n\nasync def main():\n    message = ai.Message(\n        role="user",\n        contents=[\n            ai.Part.image_from_url(\n                "https://upload.wikimedia.org/wikipedia/commons/b/bd/Golden_Retriever_Dukedestiny01_drvd.jpg"\n            ),\n            ai.Part.Text("What do you see in this image?"),\n        ],\n    )\n    lm = ai.LangModel.new_stream_api(\n        spec="OpenAI",\n        model_name="gpt-4o",\n        api_key="<OPENAI_API_KEY>",\n    )\n    agent = ai.Agent(lm)\n    async for resp in agent.run([message]):\n        if isinstance(resp.message.contents[0], ai.Part.Text):\n            print(resp.message.contents[0].text)\n\n\nif __name__ == "__main__":\n    asyncio.run(main())\n\n'})})}),(0,i.jsx)(a,{value:"javascript",label:"JavaScript",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",metastring:"showLineNumbers",children:'import * as ai from "ailoy-node";\n\nasync function main() {\n  const message = {\n    role: "user",\n    contents: [\n      ai.imageFromUrl(\n        "https://upload.wikimedia.org/wikipedia/commons/b/bd/Golden_Retriever_Dukedestiny01_drvd.jpg"\n      ),\n      { type: "text", text: "What do you see in this image?" },\n    ],\n  };\n  const lm = await ai.LangModel.newStreamAPI(\n    "OpenAI",\n    "gpt-4o",\n    "<OPENAI_API_KEY>"\n  );\n  const agent = new ai.Agent(lm);\n  for await (const resp of agent.run([message])) {\n    if (resp.message.contents[0].type === "text") {\n      console.log(resp.message.contents[0].text);\n    }\n  }\n}\n\nmain().catch((err) => {\n  console.error("Error:", err);\n});\n'})})})]}),"\n",(0,i.jsx)(n.p,{children:"Then the output looks like"}),"\n",(0,i.jsx)(o,{children:"This image shows a Golden Retriever standing in an outdoor setting. The dog has a light, cream-colored coat and is wearing a collar. The background includes grass and some foliage."}),"\n",(0,i.jsx)(n.admonition,{type:"info",children:(0,i.jsxs)(n.p,{children:["Gemini does not support URL image inputs. Use base64 image input instead as\ndescribed in ",(0,i.jsx)(n.a,{href:"#feeding-an-image-file",children:(0,i.jsx)(n.strong,{children:"Feeding an Image File"})}),"."]})}),"\n",(0,i.jsx)(n.h2,{id:"feeding-an-image-file",children:"Feeding an Image File"}),"\n",(0,i.jsx)(n.p,{children:"Also, you can read an image from a local file and include it directly as input."}),"\n",(0,i.jsxs)(t,{groupId:"code-language",children:[(0,i.jsx)(a,{value:"python",label:"Python",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",metastring:"showLineNumbers",children:'import asyncio\nfrom pathlib import Path\n\nimport ailoy as ai\n\n\nasync def main():\n    data = Path("dog.jpg").read_bytes()\n\n    message = ai.Message(\n        role="user",\n        contents=[\n            ai.Part.image_from_bytes(data),\n            ai.Part.Text("What do you see in this image?"),\n        ],\n    )\n    lm = ai.LangModel.new_stream_api(\n        spec="OpenAI",\n        model_name="gpt-4o",\n        api_key="<OPENAI_API_KEY>",\n    )\n    agent = ai.Agent(lm)\n    async for resp in agent.run([message]):\n        if isinstance(resp.message.contents[0], ai.Part.Text):\n            print(resp.message.contents[0].text)\n\n\nif __name__ == "__main__":\n    asyncio.run(main())\n\n'})})}),(0,i.jsx)(a,{value:"javascript",label:"JavaScript",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",metastring:"showLineNumbers",children:'import * as ai from "ailoy-node";\nimport * as fs from "fs";\n\nasync function main() {\n  const data = fs.readFileSync("dog.jpg");\n\n  const message = {\n    role: "user",\n    contents: [\n      ai.imageFromData(data),\n      { type: "text", text: "What do you see in this image?" },\n    ],\n  };\n  const lm = await ai.LangModel.newStreamAPI(\n    "OpenAI",\n    "gpt-4o",\n    "<OPENAI_API_KEY>"\n  );\n  const agent = new ai.Agent(lm);\n  for await (const resp of agent.run([message])) {\n    if (resp.message.contents[0].type === "text") {\n      console.log(resp.message.contents[0].text);\n    }\n  }\n}\n\nmain().catch((err) => {\n  console.error("Error:", err);\n});\n'})})})]}),"\n",(0,i.jsx)(n.p,{children:"This will produce the same output."})]})}function m(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}function g(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}},8453:(e,n,a)=>{a.d(n,{R:()=>o,x:()=>r});var t=a(6540);const i={},s=t.createContext(i);function o(e){const n=t.useContext(s);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);