"use strict";(self.webpackChunkailoy_docs=self.webpackChunkailoy_docs||[]).push([[282],{4398:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"concepts/chat-completion-format","title":"Chat Completion Format","description":"Conventionally, in a chat completion setup, both input and output follow","source":"@site/docs/concepts/chat-completion-format.mdx","sourceDirName":"concepts","slug":"/concepts/chat-completion-format","permalink":"/ailoy/docs/concepts/chat-completion-format","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"documentSidebar","previous":{"title":"Architecture","permalink":"/ailoy/docs/concepts/architecture"},"next":{"title":"Available Models","permalink":"/ailoy/docs/resources/available-models"}}');var i=t(4848),r=t(8453);const o={},l="Chat Completion Format",a={},c=[{value:"Message",id:"message",level:2},{value:"Role",id:"role",level:3},{value:"Contents",id:"contents",level:3},{value:"Part",id:"part",level:3},{value:"Delta",id:"delta",level:3},{value:"Tool",id:"tool",level:2},{value:"Tool Description",id:"tool-description",level:3},{value:"Tool Call",id:"tool-call",level:3},{value:"Tool Response",id:"tool-response",level:3},{value:"Document",id:"document",level:2}];function d(e){const n={a:"a",admonition:"admonition",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"chat-completion-format",children:"Chat Completion Format"})}),"\n",(0,i.jsxs)(n.p,{children:["Conventionally, in a chat completion setup, both ",(0,i.jsx)(n.strong,{children:"input"})," and ",(0,i.jsx)(n.strong,{children:"output"})," follow\na structured format.",(0,i.jsx)(n.br,{}),"\n","Messages are typically represented as follows:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'[\n  {\n    "role": "system",\n    "contents": [\n      { "type": "text", "text": "You are a friendly and knowledgeable assistant." }\n    ]\n  },\n  {\n    "role": "user",\n    "contents": [\n      { "type": "text", "text": "Can you explain how photosynthesis works?" }\n    ]\n  }\n]\n'})}),"\n",(0,i.jsx)(n.p,{children:"When it is executed, the output might look like:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'{\n    "role": "assistant",\n    "contents": [\n        {\n            "type": "text",\n            "text": "Photosynthesis is the process by which plants convert sunlight, water, and carbon dioxide into energy. They use sunlight to produce glucose (a form of sugar) and release oxygen as a byproduct."\n        }\n    ]\n}\n'})}),"\n",(0,i.jsxs)(n.admonition,{type:"info",children:[(0,i.jsx)(n.p,{children:"Please refer to followings for more about this schema."}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://huggingface.co/docs/transformers/main/chat_templating",children:"Transformers apply_chat_template"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://platform.openai.com/docs/api-reference/chat/create",children:"OpenAI chat completion API"})}),"\n"]})]}),"\n",(0,i.jsx)(n.h2,{id:"message",children:"Message"}),"\n",(0,i.jsxs)(n.p,{children:["A ",(0,i.jsx)(n.code,{children:"Message"})," represents one conversational turn \u2014 what one participant (system,\nuser, or assistant) says or does."]}),"\n",(0,i.jsx)(n.p,{children:"Each message contains:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["a ",(0,i.jsx)(n.strong,{children:"role"}),", indicating who is speaking,"]}),"\n",(0,i.jsxs)(n.li,{children:["a set of ",(0,i.jsx)(n.strong,{children:"contents"}),", describing what was said or sent."]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"role",children:"Role"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Role"}),(0,i.jsx)(n.th,{children:"Description"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"System"})}),(0,i.jsx)(n.td,{children:"System instructions and constraints provided to the assistant. It usually defines the model\u2019s behavior or persona."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"User"})}),(0,i.jsx)(n.td,{children:"Contents authored by the user."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Assistant"})}),(0,i.jsx)(n.td,{children:"Contents automatically generated by the assistant / AI model."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Tool"})}),(0,i.jsx)(n.td,{children:"Execution results produced by external tools / functions."})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"contents",children:"Contents"}),"\n",(0,i.jsxs)(n.p,{children:["What is said from each role is generally referred to as content.",(0,i.jsx)(n.br,{}),"\n","However, a model can operate in different modes, producing outputs that serve\ndifferent purposes. These outputs reflect the ",(0,i.jsx)(n.strong,{children:"intention"})," behind what the\nmodel says or performs."]}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Intent"}),(0,i.jsx)(n.th,{children:"Description"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Content"})}),(0,i.jsx)(n.td,{children:"General output."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Thinking(Reasoning)"})}),(0,i.jsx)(n.td,{children:"Some model generates intermediate thoughts or thinking traces before producing the final answer. These are stored in the thinking field (often hidden from the user) and can help trace or visualize the model\u2019s internal decision process."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Tool call"})}),(0,i.jsx)(n.td,{children:"When the model decides to invoke an external function or API instead of generating plain text. These are represented as structured objects that describe which function to call(name) and with what arguments."})]})]})]}),"\n",(0,i.jsx)(n.p,{children:"These types of outputs are stored in separate fields within a message, making it\npossible to distinguish from general conversation."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Example"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'[\n  Message {\n      role: "assistant",\n      thinking: "Let\u2019s reason step by step: photosynthesis converts light energy into chemical energy...",\n      contents: [\n          { type: "text", text: "Photosynthesis is the process by which plants convert sunlight, water, and carbon dioxide into energy." }\n      ],\n      tool_calls: [\n          {\n            type: "function",\n            function: {\n              id: "func_call_1234abcd",\n              name: "get_current_location",\n              arguments: ...\n            }\n          }\n      ],\n  },\n]\n'})}),"\n",(0,i.jsx)(n.h3,{id:"part",children:"Part"}),"\n",(0,i.jsxs)(n.p,{children:["While ",(0,i.jsx)(n.code,{children:"Contents"})," describe the intention of a message, ",(0,i.jsx)(n.code,{children:"Part"})," defines the ",(0,i.jsx)(n.strong,{children:"data\ntype"})," of that message."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"Part"})," can be considered as a smallest semantic units within a conversation.\nEach ",(0,i.jsx)(n.code,{children:"Message"})," contains a list of ",(0,i.jsx)(n.code,{children:"Part"})," objects. A ",(0,i.jsx)(n.code,{children:"Part"})," can represent text,\nimages, function calls, or any structured values, enabling rich multimodal\ncommunication."]}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Part"}),(0,i.jsx)(n.th,{children:"Description"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Text"})}),(0,i.jsx)(n.td,{children:"Natural-language text content"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Image"})}),(0,i.jsx)(n.td,{children:"Visual data or reference (e.g., binary, URL, or metadata)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Function"})}),(0,i.jsx)(n.td,{children:"Structured tool or function invocation"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Value"})}),(0,i.jsx)(n.td,{children:"Arbitrary data (numbers, objects, JSON values, etc.)"})]})]})]}),"\n",(0,i.jsx)(n.p,{children:"For example, if a user asks about an image, the message could look like this:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'contents: [\n  {type: "image", "image": {data: "..."}}\n  {type: "text", text: "What you can see in this image?"}\n]\n'})}),"\n",(0,i.jsx)(n.p,{children:"Together, these parts express Ailoy\u2019s multimodal conversation."}),"\n",(0,i.jsx)(n.h3,{id:"delta",children:"Delta"}),"\n",(0,i.jsxs)(n.p,{children:["The inference of a language model can take a significant amount of time. To\nimprove real-time responsiveness, many AI systems stream tokens as they are\ngenerated. These streamed outputs are typically delivered in the form of\n",(0,i.jsx)(n.strong,{children:"deltas"}),"."]}),"\n",(0,i.jsxs)(n.p,{children:["A ",(0,i.jsx)(n.strong,{children:"delta"}),"(",(0,i.jsx)(n.code,{children:"MessageDelta"})," or ",(0,i.jsx)(n.code,{children:"PartDelta"}),") represents an output of this\nstep(inference) updated during a streaming response. As the model generates text\ntoken by token, each incremental addition is emitted as a delta, which is later\nmerged into a complete ",(0,i.jsx)(n.code,{children:"Message"}),"."]}),"\n",(0,i.jsxs)(n.p,{children:["Ailoy provides a simple way to retrieve and aggregate deltas. One can use\n",(0,i.jsx)(n.code,{children:"accumulate"})," and ",(0,i.jsx)(n.code,{children:"finish"})," function."]}),"\n",(0,i.jsx)(n.h2,{id:"tool",children:"Tool"}),"\n",(0,i.jsx)(n.p,{children:"A Tool enables the model to act \u2014 to execute external functions, access APIs, or\nperform any operation beyond plain text generation."}),"\n",(0,i.jsx)(n.p,{children:"Each tool has two halves:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Description (declarative) \u2014 defines what the tool is and how it can be called."}),"\n",(0,i.jsx)(n.li,{children:"Behavior (imperative) \u2014 defines what your code actually does when the tool is\ninvoked."}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Together, they allow the model to dynamically invoke external capabilities while\nkeeping reasoning and execution logically separated."}),"\n",(0,i.jsxs)(n.admonition,{type:"info",children:[(0,i.jsx)(n.p,{children:"Please refer to following resources for more about the tool schema convention."}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://huggingface.co/docs/transformers/main/chat_extras",children:"Transformers tool_use"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://platform.openai.com/docs/api-reference/chat/create#chat-create-tool_choice-function-tool-choice",children:"OpenAI chat completion API"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://modelcontextprotocol.io/specification/2025-06-18/server/tools#data-types",children:"MCP"})}),"\n"]})]}),"\n",(0,i.jsx)(n.h3,{id:"tool-description",children:"Tool Description"}),"\n",(0,i.jsx)(n.p,{children:"Ailoy follows a JSON-Schema-like convention to describe tool arguments and\noptional return schemas. This ensures that language models can reliably\nconstruct valid function calls \u2014 the schema precisely defines the allowed\nparameters, required fields, and expected return structure."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'{\n  "name": "get_temperature",\n  "description": "Retrieve current temperature for a specific city.",\n  "parameters": {\n    "type": "object",\n    "required": ["city"],\n    "properties": {\n      "city": { "type": "string", "description": "City name" },\n      "unit": { "type": "string", "enum": ["celcius", "fahrenheit"], "default": "celcius" }\n    },\n    "additionalProperties": false\n  },\n  "returns": {\n    "type": "number"\n  }\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"tool-call",children:"Tool Call"}),"\n",(0,i.jsx)(n.p,{children:"When a model decides to use a tool instead of generating plain text, it emits a\ntool call. This occurs inside an assistant message \u2014 since the assistant is the\none deciding to call a tool \u2014 but the call is placed inside the tool_calls field\n(not contents)."}),"\n",(0,i.jsx)(n.p,{children:"A typical tool call message looks like this:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'{\n  "role": "assistant",\n  "contents": [\n    { "type": "text", "text": "Let me check the current weather for you." }\n  ],\n  "tool_calls": [\n    {\n      "type": "function",\n      "function": {\n        "name": "get_weather",\n        "arguments": { "city": "Seoul", "unit": "celcius" }\n      },\n      "id": "call_01HZX2..."\n    }\n  ]\n}\n'})}),"\n",(0,i.jsx)(n.p,{children:"Explanation:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["The assistant outputs a structured tool call in ",(0,i.jsx)(n.code,{children:"tool_calls"})," segment."]}),"\n",(0,i.jsx)(n.li,{children:"The runtime then executes the corresponding function based on its name and\narguments."}),"\n",(0,i.jsxs)(n.li,{children:["The ",(0,i.jsx)(n.code,{children:"id"})," field can optionally be tagged, which uniquely identifies this tool\ncall, allowing the tool\u2019s response to be correctly linked."]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"tool-response",children:"Tool Response"}),"\n",(0,i.jsxs)(n.p,{children:['Once the runtime executes the tool\u2019s behavior, it must append a new message to\nthe conversation, with the role set to "tool". Also, the result is stored inside\nthe ',(0,i.jsx)(n.code,{children:"contents"})," field."]}),"\n",(0,i.jsx)(n.p,{children:"For example"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'{\n  "role": "tool",\n  "tool_call_id": "call_01HZX2...",\n  "name": "get_weather",\n  "contents": [\n    { "type": "text", "text": "12.3" }\n  ]\n}\n'})}),"\n",(0,i.jsx)(n.p,{children:"When an error occurs in a tool, it should still be passed along so that the\nmodel can recognize and handle it."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'{\n  "role": "tool",\n  "tool_call_id": "call_01HZX2...",\n  "name": "get_weather",\n  "contents": [\n    { "type": "text", "text": "{ \\"code\\": \\"NOT_FOUND\\" }" }\n  ]\n}\n'})}),"\n",(0,i.jsx)(n.h2,{id:"document",children:"Document"}),"\n",(0,i.jsxs)(n.p,{children:["A ",(0,i.jsx)(n.strong,{children:"Document"})," is the normalized representation of any retrievable knowledge\nitem. It consists of two components: a ",(0,i.jsx)(n.strong,{children:"title"})," and a ",(0,i.jsx)(n.strong,{children:"text body"}),"."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'{\n  "title": "...",\n  "text": "..."\n}\n'})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.code,{children:"title"})})," A short, descriptive label that helps identify the document. The\ntitle is ",(0,i.jsx)(n.strong,{children:"not used as part of model inference"})," \u2014 it is primarily for\nindexing, display, and retrieval ranking. You can think of it as metadata or a\nsummary, similar to a filename or headline."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.code,{children:"text"})})," The actual ",(0,i.jsx)(n.strong,{children:"content"})," of the document. This field is fed directly\ninto the language model during retrieval-augmented inference. It contains the\nmeaningful information that the model can read, reason about, and use to\ngenerate responses."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["All retrieved knowledge sources (e.g., from vector databases, APIs, or local\nfiles) are normalized into this unified ",(0,i.jsx)(n.code,{children:'"document"'})," format before being passed\nto the model. This ensures that, regardless of the original source or schema,\nthe model always receives consistent input."]}),"\n",(0,i.jsx)(n.p,{children:"For example:"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Source"}),(0,i.jsx)(n.th,{children:"Normalized as"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Web article"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:'{ "title": "Article Title", "text": "Full article content..." }'})})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"PDF extract"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:'{ "title": "File: research.pdf", "text": "Extracted paragraph..." }'})})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Knowledge base entry"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:'{ "title": "FAQ: Model Loading", "text": "To load a model, use..." }'})})]})]})]}),"\n",(0,i.jsx)(n.p,{children:"This design simplifies retrieval and unifies downstream processing within\nAiloy\u2019s knowledge pipeline."})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>l});var s=t(6540);const i={},r=s.createContext(i);function o(e){const n=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);