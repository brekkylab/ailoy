"use strict";(self.webpackChunkailoy_docs=self.webpackChunkailoy_docs||[]).push([[480],{6832:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>u,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"tutorial/multi-turn-conversation","title":"Multi-turn conversation","description":"Multi-turn conversation is a basic feature of the LLM applications, which implements a continuous flow of conversation by providing context for multiple stages of interactions.","source":"@site/docs/tutorial/multi-turn-conversation.mdx","sourceDirName":"tutorial","slug":"/tutorial/multi-turn-conversation","permalink":"/ailoy/docs/tutorial/multi-turn-conversation","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"documentSidebar","previous":{"title":"Getting started","permalink":"/ailoy/docs/tutorial/getting-started"},"next":{"title":"Reasoning","permalink":"/ailoy/docs/tutorial/reasoning"}}');var r=t(4848),a=t(8453);const o={},i="Multi-turn conversation",l={},c=[{value:"Using Agent",id:"using-agent",level:2},{value:"Overriding system messages",id:"overriding-system-messages",level:3},{value:"Using Runtime APIs",id:"using-runtime-apis",level:2},{value:"Overriding system message",id:"overriding-system-message",level:3}];function d(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",p:"p",pre:"pre",strong:"strong",...(0,a.R)(),...e.components},{TabItem:t,Tabs:s}=n;return t||m("TabItem",!0),s||m("Tabs",!0),(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"multi-turn-conversation",children:"Multi-turn conversation"})}),"\n",(0,r.jsx)(n.p,{children:"Multi-turn conversation is a basic feature of the LLM applications, which implements a continuous flow of conversation by providing context for multiple stages of interactions."}),"\n",(0,r.jsx)(n.h2,{id:"using-agent",children:"Using Agent"}),"\n",(0,r.jsxs)(n.p,{children:["Ailoy's high-level API ",(0,r.jsx)(n.code,{children:"Agent"})," maintains the query/response history, so a multi-turn conversation with LLM can be implemented naturally by repeatedly sending queries to ",(0,r.jsx)(n.code,{children:"Agent"})," and receiving the responses  in the code context."]}),"\n",(0,r.jsxs)(s,{groupId:"code-language",children:[(0,r.jsx)(t,{value:"python",label:"Python",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",metastring:"showLineNumbers",children:'with Agent(...) as agent:\n    while True:\n        query = input("\\nUser: ")\n\n        if query == "exit":\n            break\n        if query == "":\n            continue\n\n        for resp in agent.query(query):\n            agent.print(resp)\n'})})}),(0,r.jsx)(t,{value:"node",label:"JavaScript(Node)",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",metastring:"showLineNumbers",children:'const agent = await defineAgent(...);\nwhile (true) {\n  const query = await getUserInput("User: ");\n\n  if (query === "exit")\n    break;\n  if (query === "")\n    continue;\n\n  process.stdout.write(`\\nAssistant: `);\n  for await (const resp of agent.query(query)) {\n    agent.print(resp);\n  }\n}\nawait agent.delete();\n'})})})]}),"\n",(0,r.jsx)(n.h3,{id:"overriding-system-messages",children:"Overriding system messages"}),"\n",(0,r.jsxs)(n.p,{children:["To override system message, you can pass the system message string as the optional ",(0,r.jsx)(n.code,{children:"system_message"})," argument when you create your agent instance."]}),"\n",(0,r.jsxs)(s,{groupId:"code-language",children:[(0,r.jsx)(t,{value:"python",label:"Python",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",metastring:"showLineNumbers",children:'with Agent(\n    rt,\n    model_name="Qwen/Qwen3-8B",\n    system_message="You are a friendly chatbot who always responds in the style of a pirate.",\n) as agent:\n    for resp in agent.query("Please give me a short poem about AI"):\n        agent.print(resp)\n'})})}),(0,r.jsx)(t,{value:"node",label:"JavaScript(Node)",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",metastring:"showLineNumbers",children:'const agent = await defineAgent(rt, "Qwen/Qwen3-8B", {\n  systemMessage:\n    "You are a friendly chatbot who always responds in the style of a pirate.",\n});\n\nfor await (const resp of agent.query("Please give me a short poem about AI")) {\n  agent.print(resp);\n}\nawait agent.delete();\n'})})})]}),"\n",(0,r.jsx)(n.h2,{id:"using-runtime-apis",children:"Using Runtime APIs"}),"\n",(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsxs)(n.p,{children:["Refer to ",(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"calling-low-level-apis",children:"Calling low-level APIs"})})," for more information about using the low-level ",(0,r.jsx)(n.code,{children:"Runtime"})," API."]})}),"\n",(0,r.jsxs)(n.p,{children:["You can put the context of freely structured conversations into Ailoy's low-level ",(0,r.jsx)(n.code,{children:"Runtime"})," API calls for more advanced multi-turn conversation. e.g. ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.a,{href:"https://arxiv.org/abs/2201.11903",children:"Chain-of-Thought Prompting"})})]}),"\n",(0,r.jsx)(n.p,{children:"In theory, an LLM generates responses based only on the context provided at the moment\u2014it doesn't retain memory of past interactions by itself. Therefore, to receive an appropriate response in an ongoing conversation with an LLM, you must provide the entire conversation history up to that point each time you make a request."}),"\n",(0,r.jsxs)(s,{groupId:"code-language",children:[(0,r.jsx)(t,{value:"python",label:"Python",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",metastring:"showLineNumbers",children:'with Runtime() as rt:\n    rt.define("tvm_language_model", "lm0", {"model": "Qwen/Qwen3-8B"})\n\n    messages = [\n        {"role": "user", "content": "if a>1, what is the sum of the real solutions of \'sqrt(a-sqrt(a+x))=x\'?"},\n        {"role": "assistant", "content": "Let\'s think step by step."},  # Chain-of-Thought prompt\n    ]\n\n    for resp in rt.call_iter_method("lm0", "infer", {"messages": messages}):\n        print(resp["message"]["content"], end=\'\')\n\n    rt.delete("lm0")\n'})})}),(0,r.jsx)(t,{value:"node",label:"JavaScript(Node)",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",metastring:"showLineNumbers",children:'const rt = await startRuntime();\n\nawait rt.define("tvm_language_model", "lm0", {\n  model: "Qwen/Qwen3-8B",\n});\n\nconst messages = [\n  { role: "user", content: "if a>1, what is the sum of the real solutions of \'sqrt(a-sqrt(a+x))=x\'?" },\n  { role: "assistant", content: "Let\'s think step by step." },  // Chain-of-Thought prompt\n]\n\nfor await (const resp of rt.callIterMethod("lm0", "infer", { messages: messages })) {\n  console.log(resp);\n}\n\nawait rt.delete("lm0");\n\nawait rt.stop();\n'})})})]}),"\n",(0,r.jsx)(n.h3,{id:"overriding-system-message",children:"Overriding system message"}),"\n",(0,r.jsxs)(n.p,{children:["To override the system message, you can include a message with ",(0,r.jsx)(n.code,{children:'"role": "system"'})," as the first element in the context messages array."]}),"\n",(0,r.jsxs)(s,{groupId:"code-language",children:[(0,r.jsx)(t,{value:"python",label:"Python",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",metastring:"showLineNumbers",children:'with Runtime() as rt:\n    rt.define("tvm_language_model", "lm0", {"model": "Qwen/Qwen3-8B"})\n\n    messages = [\n        {"role": "system", "content": "You are a friendly chatbot who always responds in the style of a pirate."},\n        {"role": "user", "content": "Who are you?"},\n    ]\n\n    for resp in rt.call_iter_method("lm0", "infer", {"messages": messages}):\n        print(resp["message"]["content"], end=\'\')\n\n    rt.delete("lm0")\n'})})}),(0,r.jsx)(t,{value:"node",label:"JavaScript(Node)",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",metastring:"showLineNumbers",children:'const rt = await startRuntime();\n\nawait rt.define("tvm_language_model", "lm0", {\n  model: "Qwen/Qwen3-8B",\n});\n\nconst messages = [\n  { role: "system", content: "You are a friendly chatbot who always responds in the style of a pirate." },\n  { role: "user", content: "Who are you?" },\n]\n\nfor await (const resp of rt.callIterMethod("lm0", "infer", { messages: messages })) {\n  console.log(resp);\n}\n\nawait rt.delete("lm0");\n\nawait rt.stop();\n'})})})]})]})}function u(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}function m(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>i});var s=t(6540);const r={},a=s.createContext(r);function o(e){const n=s.useContext(a);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),s.createElement(a.Provider,{value:n},e.children)}}}]);